{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXATwZ8VxZG7"
      },
      "source": [
        "# MPI\n",
        "\n",
        " Murilo Boratto$^1$\n",
        "\n",
        "$^1$ SENAI CIMATEC <br />\n",
        "     &nbsp;&nbsp;&nbsp; Centro de Supercomputação<br />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyB9gzUjSGKc"
      },
      "source": [
        "## Instalação  MPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orxl23v_xqVe"
      },
      "source": [
        "Este é o passo a passo de como instalar o MPI em ambiente virtual do Colab, utilizando a implementação open source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIWeteLFbMdM",
        "outputId": "779ddd6b-bf90-44ec-aef5-8358d764d50c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  hwloc-nox libmpich-dev libmpich12 libslurm37\n",
            "Suggested packages:\n",
            "  mpich-doc\n",
            "The following NEW packages will be installed:\n",
            "  hwloc-nox libmpich-dev libmpich12 libslurm37 mpich\n",
            "0 upgraded, 5 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 14.2 MB of archives.\n",
            "After this operation, 102 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libslurm37 amd64 21.08.5-2ubuntu1 [542 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 hwloc-nox amd64 2.7.0-2ubuntu1 [205 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpich12 amd64 4.0-3 [5,866 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mpich amd64 4.0-3 [197 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpich-dev amd64 4.0-3 [7,375 kB]\n",
            "Fetched 14.2 MB in 2s (6,773 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libslurm37.\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../libslurm37_21.08.5-2ubuntu1_amd64.deb ...\n",
            "Unpacking libslurm37 (21.08.5-2ubuntu1) ...\n",
            "Selecting previously unselected package hwloc-nox.\n",
            "Preparing to unpack .../hwloc-nox_2.7.0-2ubuntu1_amd64.deb ...\n",
            "Unpacking hwloc-nox (2.7.0-2ubuntu1) ...\n",
            "Selecting previously unselected package libmpich12:amd64.\n",
            "Preparing to unpack .../libmpich12_4.0-3_amd64.deb ...\n",
            "Unpacking libmpich12:amd64 (4.0-3) ...\n",
            "Selecting previously unselected package mpich.\n",
            "Preparing to unpack .../archives/mpich_4.0-3_amd64.deb ...\n",
            "Unpacking mpich (4.0-3) ...\n",
            "Selecting previously unselected package libmpich-dev:amd64.\n",
            "Preparing to unpack .../libmpich-dev_4.0-3_amd64.deb ...\n",
            "Unpacking libmpich-dev:amd64 (4.0-3) ...\n",
            "Setting up libslurm37 (21.08.5-2ubuntu1) ...\n",
            "Setting up hwloc-nox (2.7.0-2ubuntu1) ...\n",
            "Setting up libmpich12:amd64 (4.0-3) ...\n",
            "Setting up mpich (4.0-3) ...\n",
            "Setting up libmpich-dev:amd64 (4.0-3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install libopenmpi-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823d_hqHqTdN"
      },
      "source": [
        "### Hello World!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hTtR30ikC5N",
        "outputId": "a39a9d38-8581-4e06-b134-50a769a4c0f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing hello-mpi.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile hello-mpi.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char ** argv)\n",
        "{\n",
        "    int rank, size;\n",
        "\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    printf(\"Hello World from process %d of %d\\n\", rank, size);\n",
        "\n",
        "    MPI_Finalize();\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FTVBh76aSywY"
      },
      "outputs": [],
      "source": [
        "!mpicc hello-mpi.c -o hello-mpi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCAWmPrRYc6W",
        "outputId": "71f24677-2811-4cf2-9c5d-b1fff66def9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World from process 0 of 4\n",
            "Hello World from process 1 of 4\n",
            "Hello World from process 2 of 4\n",
            "Hello World from process 3 of 4\n"
          ]
        }
      ],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./hello-mpi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edaoNwRFeJK9"
      },
      "source": [
        "### MPI #1 - Send x Recv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZpA7sUlLVgZ",
        "outputId": "4f26faa8-706f-4123-b86b-8502c6ff6f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpi-Send-Recv.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi-Send-Recv.c\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "\n",
        "int main (int argc, char *argv[])\n",
        "{\n",
        "  int a[8] = {1,2,3,4,5,6,7,8};\n",
        "  int b[8];\n",
        "\n",
        "  int numOfProcessors, rank, dest,i, tag = 1000;\n",
        "\n",
        "  MPI_Init(&argc, &argv);\n",
        "  MPI_Comm_size(MPI_COMM_WORLD, &numOfProcessors);\n",
        "  MPI_Comm_rank(MPI_COMM_WORLD,&rank);\n",
        "  MPI_Status status;\n",
        "\n",
        "  if(rank == 0){\n",
        "\n",
        "      for (dest = 1; dest < numOfProcessors; dest++)\n",
        "        MPI_Send(&a, 8, MPI_INT, dest, tag, MPI_COMM_WORLD);\n",
        "\n",
        "  }else{\n",
        "\n",
        "     MPI_Recv(&b, 8, MPI_INT, 0, tag, MPI_COMM_WORLD, &status);\n",
        "\n",
        "     for(i = 0; i < 8; i++)\n",
        "       printf(\"%d\\t\", b[i]);\n",
        "\n",
        "     printf(\"\\n\");\n",
        "\n",
        "  }\n",
        "\n",
        "  MPI_Finalize();\n",
        "\n",
        "  return 0;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W6r-gx0_Ld2G"
      },
      "outputs": [],
      "source": [
        "!mpicc mpi-Send-Recv.c -o mpi-Send-Recv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL9LL2OmLhvM",
        "outputId": "dd981edd-9abb-4823-f428-952fd0ab1b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\t2\t3\t4\t5\t6\t7\t8\t\n",
            "1\t2\t3\t4\t5\t6\t7\t8\t\n",
            "1\t2\t3\t4\t5\t6\t7\t8\t\n"
          ]
        }
      ],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4  ./mpi-Send-Recv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFTvpmQBeJK-"
      },
      "source": [
        "### MPI #2 - MPI array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B3TRZ5CeJK_",
        "outputId": "8367b413-9889-43fb-e664-509a1133dd02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpi-array.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi-array.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <mpi.h>\n",
        "\n",
        "#define  ARRAYSIZE\t16\n",
        "#define  MASTER\t\t0\n",
        "\n",
        "int  data[ARRAYSIZE];\n",
        "\n",
        "int update(int position, int sizeBlock)\n",
        "{\n",
        " int i, suma = 0;\n",
        "\n",
        " for(i = position; i < (position + sizeBlock); i++)\n",
        "   suma = suma + data[i];\n",
        "\n",
        "  return(suma);\n",
        "}\n",
        "\n",
        "\n",
        "int main (int argc, char *argv[]){\n",
        "\n",
        "\n",
        " int a[16] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16};\n",
        "\n",
        " int numtasks, taskid, dest, position, i, j, tag1=1000, tag2=2000, source, sizeBlock,\n",
        "     suma, cont, sumatotal;\n",
        "\n",
        " MPI_Init(&argc, &argv);\n",
        " MPI_Comm_size(MPI_COMM_WORLD, &numtasks); /*numtasks= number of processes*/\n",
        " MPI_Status status;\n",
        "\n",
        " int vectorSuma[numtasks];/* 4 */\n",
        "\n",
        " MPI_Comm_rank(MPI_COMM_WORLD,&taskid);\n",
        "\n",
        " sizeBlock = (ARRAYSIZE / numtasks); /* 16/4 = 4 */\n",
        "\n",
        "/************************* MASTER **************************************/\n",
        "\n",
        "  if (taskid == MASTER)\n",
        "  {\n",
        "\n",
        "  /*------ Initialize array ------------- */\n",
        "\n",
        "    for(i = 0; i < ARRAYSIZE; i++) //16\n",
        "     data[i] =  a[i];\n",
        "\n",
        "    printf(\"\\n:: (1) Initialize array :: \\n\\n\");\n",
        "\n",
        "    for(i = 0; i < ARRAYSIZE; i++)\n",
        "     printf(\"%d\\t\", data[i]);\n",
        "\n",
        "\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    position = sizeBlock;\n",
        "\n",
        "/*-------------- MASTER SEND TO WORKERS -----------------*/\n",
        "\n",
        "    printf(\"\\n:: (2) Send array parts :: \\n\");\n",
        "\n",
        "    for (dest = 1; dest < numtasks; dest++)\n",
        "    {\n",
        "      MPI_Send(&position, 1, MPI_INT, dest, tag1, MPI_COMM_WORLD);\n",
        "      MPI_Send(&data[position], sizeBlock, MPI_INT, dest, tag2, MPI_COMM_WORLD);\n",
        "\n",
        "      printf(\"\\ndata[%d]= %d origin = %d\\n\",position,data[position], dest);\n",
        "      position = position + sizeBlock;\n",
        "    }/*for*/\n",
        "\n",
        "/*--------- MASTER DATA PROCESS --------------------------*/\n",
        "\n",
        "    position = 0;\n",
        "    suma = update(position, sizeBlock) ;\n",
        "    printf(\"\\nsum Master = %d\\n\", suma);\n",
        "\n",
        "/*--------- MASTER DATA PROCESS --------------------------*/\n",
        "\n",
        "    sumatotal = suma;\n",
        "\n",
        "/*-------- MASTER RECV FROM WORKERS ------------------*/\n",
        "\n",
        "    for(i = 1; i < numtasks; i++)\n",
        "    {\n",
        "     vectorSuma[i]= suma;\n",
        "     source = i;\n",
        "\n",
        "     MPI_Recv(&suma, 1, MPI_INT, source, 3,MPI_COMM_WORLD, &status);\n",
        "\n",
        "     sumatotal+=suma;\n",
        "\n",
        "     printf(\"sum Worker = %d\\n\", suma);\n",
        "\n",
        "    }\n",
        "\n",
        "    printf(\"\\nTOTAL RESULT= %d\\n\\n\", sumatotal);\n",
        "\n",
        "   }\n",
        "\n",
        "/******************* WORKERS ***************************************************/\n",
        "\n",
        "   if (taskid > MASTER)\n",
        "   {\n",
        "    source = MASTER;\n",
        "\n",
        "    MPI_Recv(&position, 1, MPI_INT, source, tag1, MPI_COMM_WORLD, &status);\n",
        "    MPI_Recv(&data[position], sizeBlock, MPI_INT, source, tag2, MPI_COMM_WORLD, &status);\n",
        "\n",
        "   /*--------- WORKER DATA PROCESS-------------------------*/\n",
        "\n",
        "           suma = update(position,sizeBlock);\n",
        "\n",
        "   /*--------- WORKER DATA PROCESS --------------------------*/\n",
        "\n",
        "    dest = MASTER;\n",
        "\n",
        "    MPI_Send(&suma,1, MPI_INT, MASTER, 3, MPI_COMM_WORLD);\n",
        "\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "\n",
        "   return 0;\n",
        "\n",
        "}/*main*/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inrnf5OpeJK_"
      },
      "outputs": [],
      "source": [
        "!mpicc mpi-array.c -o mpi-array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfwoEnWKeJK_",
        "outputId": "371e0788-5a93-490d-bd75-193f3df99524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ":: (1) Initialize array :: \n",
            "\n",
            "1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\t13\t14\t15\t16\t\n",
            "\n",
            ":: (2) Send array parts :: \n",
            "\n",
            "data[4]= 5 origin = 1\n",
            "\n",
            "data[8]= 9 origin = 2\n",
            "\n",
            "data[12]= 13 origin = 3\n",
            "\n",
            "sum Master = 10\n",
            "sum Worker = 26\n",
            "sum Worker = 42\n",
            "sum Worker = 58\n",
            "\n",
            "TOTAL RESULT= 136\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./mpi-array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSD50A0UeJK_"
      },
      "source": [
        "### MPI #3 - MPI Sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWHlYW3AeJLA",
        "outputId": "ebfa542f-3763-4bc9-aa98-d2ba88a60209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting mpi-sort.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi-sort.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "void start(int v[], int qtd){\n",
        "\n",
        "  int i;\n",
        "\n",
        "  for(i = 0; i < qtd; i++)\n",
        "     v[i] = rand()%(100-1)*1;\n",
        "\n",
        "}\n",
        "\n",
        "void print(int v[], int qtd){\n",
        "\n",
        "  int i;\n",
        "\n",
        "  for(i = 0; i < qtd; i++)\n",
        "     printf(\"%d\\t\", v[i]);\n",
        "\n",
        "  printf(\"\\n\\n\");\n",
        "\n",
        "}\n",
        "\n",
        "void sort(int v[], int qtd){\n",
        "\n",
        "  int i, j, aux;\n",
        "  int k = qtd - 1 ;\n",
        "\n",
        "  for(i = 0; i < qtd; i++){\n",
        "     for(j = 0; j < k; j++){\n",
        "        if(v[j] > v[j+1])\n",
        "        {\n",
        "            aux = v[j];\n",
        "        v[j] = v[j+1];\n",
        "        v[j+1]=aux;\n",
        "        }\n",
        "     }\n",
        "     k--;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char ** argv)\n",
        "{\n",
        "    int rank, a[100], b[50];\n",
        "\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    if(rank == 0) {\n",
        "        start(a, 100);\n",
        "        print(a, 100);\n",
        "\n",
        "        MPI_Send(&a[50], 50, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
        "        sort(a, 50);\n",
        "        print(a, 50);\n",
        "\n",
        "        MPI_Recv(b, 50, MPI_INT, 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "        print(b, 50);\n",
        "\n",
        "        /* Serial: Merge array b and sorted part of array a */\n",
        "    }\n",
        "    else if (rank == 1) {\n",
        "        MPI_Recv(b, 50, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "        sort(b, 50);\n",
        "        MPI_Send(b, 50, MPI_INT, 0, 0, MPI_COMM_WORLD);\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jw0RGh9eJLA"
      },
      "outputs": [],
      "source": [
        "!mpicc mpi-sort.c -o mpi-sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwjdneZQeJLA",
        "outputId": "929a4879-ca3e-4295-f03b-8137469e0b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\t43\t72\t79\t23\t70\t55\t39\t69\t1\t41\t40\t5\t25\t95\t4\t42\t54\t79\t55\t98\t8\t60\t33\t26\t17\t44\t76\t91\t10\t32\t18\t54\t3\t95\t75\t73\t52\t13\t43\t51\t54\t81\t56\t77\t76\t59\t20\t29\t39\t74\t28\t46\t35\t62\t72\t50\t5\t49\t40\t15\t81\t59\t69\t83\t53\t43\t57\t4\t56\t0\t54\t9\t81\t11\t87\t56\t68\t6\t86\t7\t78\t15\t53\t14\t75\t24\t65\t80\t73\t6\t96\t53\t63\t64\t37\t16\t9\t93\t20\t\n",
            "\n",
            "1\t3\t4\t5\t8\t10\t13\t17\t18\t20\t23\t25\t26\t28\t29\t32\t33\t39\t39\t40\t41\t42\t43\t43\t44\t51\t52\t54\t54\t54\t55\t55\t56\t59\t60\t69\t70\t72\t73\t75\t76\t76\t77\t79\t79\t81\t91\t95\t95\t98\t\n",
            "\n",
            "0\t4\t5\t6\t6\t7\t9\t9\t11\t14\t15\t15\t16\t20\t24\t28\t35\t37\t40\t43\t46\t49\t50\t53\t53\t53\t54\t56\t56\t57\t59\t62\t63\t64\t65\t68\t69\t72\t73\t74\t75\t78\t80\t81\t81\t83\t86\t87\t93\t96\t\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 2 ./mpi-sort"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYP1lJrZok32"
      },
      "source": [
        "### MPI #4 - MPI_Bcast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH8IX1MAok33",
        "outputId": "4f03ceea-a1db-43f6-d061-75a36957be82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpiBcast.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpiBcast.c\n",
        "#include <mpi.h>\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "\n",
        "void print_vector(int rank, int *in, int n, int label){\n",
        "\n",
        " if(label)\n",
        "  printf(\"[%d]\\t\", rank);\n",
        "   else\n",
        "     printf(\"  \\t\");\n",
        "\n",
        " for(int i=0; i < n; i++)\n",
        "  printf(\"%d\\t\", in[i]);\n",
        "\n",
        " printf(\"\\n\");\n",
        "\n",
        "}\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "\n",
        "  int i, rank, size;\n",
        "\n",
        "  MPI_Init (&argc, &argv);\n",
        "  MPI_Comm_rank (MPI_COMM_WORLD, &rank);\n",
        "  MPI_Comm_size (MPI_COMM_WORLD, &size);\n",
        "\n",
        "  int data_size = 8;\n",
        "\n",
        "  int *data  = (int*) malloc(data_size * sizeof(int));\n",
        "\n",
        "  if(rank == 0) {\n",
        "      for(int i = 0; i < data_size; i++)\n",
        "         data[i] = rand()%(10-2)*2;\n",
        "\n",
        "      print_vector(rank, data, data_size, 0);\n",
        "  }\n",
        "\n",
        "  MPI_Bcast(data, data_size, MPI_INT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "  for(int i = 0; i < data_size; i++)\n",
        "      data[i] *= 2;\n",
        "\n",
        "  print_vector(rank, data, data_size, 1);\n",
        "\n",
        "  MPI_Finalize();\n",
        "\n",
        "  return 0;\n",
        "\n",
        "}/*main*/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXKV9XKZok33"
      },
      "outputs": [],
      "source": [
        "!mpicxx mpiBcast.c -o mpiBcast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAg-VF-qok33",
        "outputId": "901b7452-940a-41d2-a4fa-7fa60bab5fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \t14\t12\t2\t6\t2\t14\t4\t8\t\n",
            "[0]\t28\t24\t4\t12\t4\t28\t8\t16\t\n",
            "[1]\t28\t24\t4\t12\t4\t28\t8\t16\t\n",
            "[3]\t28\t24\t4\t12\t4\t28\t8\t16\t\n",
            "[2]\t28\t24\t4\t12\t4\t28\t8\t16\t\n"
          ]
        }
      ],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./mpiBcast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ETM5MEok34"
      },
      "source": [
        "### MPI #5 - MPI_Reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8uGC3h2ok34",
        "outputId": "1cc22f1e-add4-4359-cbca-f393063d4ae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpiReduce.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpiReduce.c\n",
        "#include <mpi.h>\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "\n",
        "void print_vector(double *in, int n){\n",
        "\n",
        " for(int i=0; i < n; i++)\n",
        "  printf(\"%1.2f\\t\", in[i]);\n",
        "\n",
        " printf(\"\\n\");\n",
        "\n",
        "}/*print_vector*/\n",
        "\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "\n",
        "  int i, rank, size;\n",
        "  double result = 0, result_f;\n",
        "\n",
        "  MPI_Init (&argc, &argv);\n",
        "  MPI_Comm_rank (MPI_COMM_WORLD, &rank);\n",
        "  MPI_Comm_size (MPI_COMM_WORLD, &size);\n",
        "\n",
        "  int data_size = 8;\n",
        "\n",
        "  double *x  = (double*) malloc(data_size * sizeof(double));\n",
        "  double *y  = (double*) malloc(data_size * sizeof(double));\n",
        "\n",
        "  for(int i = 0; i < data_size; i++){\n",
        "      x[i] = 1;\n",
        "      y[i] = 2;\n",
        "      result = result + x[i] * y[i];\n",
        "  }\n",
        "\n",
        "  if(rank == 0 || rank){\n",
        "    printf(\"Rank %d\\n\", rank);\n",
        "    print_vector(x, data_size);\n",
        "    print_vector(y, data_size);\n",
        "  }\n",
        "\n",
        "  MPI_Reduce(&result, &result_f, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);\n",
        "\n",
        "  if(rank == 0)\n",
        "    printf(\"dot(x,y) = %f\\n\", result_f);\n",
        "\n",
        "  MPI_Finalize();\n",
        "\n",
        "  return 0;\n",
        "\n",
        "}/*main*/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2atA13E5ok34"
      },
      "outputs": [],
      "source": [
        "!mpicxx mpiReduce.c -o mpiReduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypwqlaMDok34",
        "outputId": "a93b9211-c0e2-4ad1-8971-a552334a1f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rank 1\n",
            "1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t\n",
            "Rank 0\n",
            "1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t\n",
            "2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t\n",
            "2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t\n",
            "dot(x,y) = 32.000000\n"
          ]
        }
      ],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 2 ./mpiReduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdvRV7cpok35"
      },
      "source": [
        "### MPI #6 - MPI_Gather"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe86m-SOok35",
        "outputId": "aefd3484-2d55-4feb-fdbd-0d0463083563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpiGather.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpiGather.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <mpi.h>\n",
        "\n",
        "int main( int argc, char **argv){\n",
        "\n",
        "int isend;\n",
        "int *irecv = (int *) calloc (4, sizeof(int));\n",
        "int rank, size;\n",
        "\n",
        "MPI_Init( &argc, &argv );\n",
        "MPI_Comm_rank( MPI_COMM_WORLD, &rank );\n",
        "MPI_Comm_size( MPI_COMM_WORLD, &size );\n",
        "\n",
        "isend = rank + 1;\n",
        "\n",
        "MPI_Gather(&isend, 1, MPI_INT, irecv, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "if(rank == 0)\n",
        "  printf(\"rank = %d\\tisend = %d\\tirecv = %d %d %d %d\\n\", rank, isend, irecv[0], irecv[1], irecv[2], irecv[3]);\n",
        "    else\n",
        "       printf(\"rank = %d\\tisend = %d\\tirecv = %d %d %d %d\\n\", rank, isend, irecv[0], irecv[1], irecv[2], irecv[3]);\n",
        "\n",
        "free(irecv);\n",
        "\n",
        "MPI_Finalize();\n",
        "\n",
        "return 0;\n",
        "\n",
        "}/*main*/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMn4HwLZok35"
      },
      "outputs": [],
      "source": [
        "!mpicc mpiGather.c -o mpiGather"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFg4_yG3ok35",
        "outputId": "f23bafaa-d6c9-4fc4-cf74-9e2e2c337d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rank = 0\tisend = 1\tirecv = 1 2 0 0\n",
            "rank = 1\tisend = 2\tirecv = 0 0 0 0\n"
          ]
        }
      ],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 2 ./mpiGather"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WssBIJjCok36"
      },
      "source": [
        "### MPI #7 - MPI_Scatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bEL5Fe_ok36"
      },
      "outputs": [],
      "source": [
        "\n",
        "                +-----------------------+\n",
        "                |       Process 0       |\n",
        "                +-----+-----+-----+-----+\n",
        "                |  0  | 100 | 200 | 300 |\n",
        "                +-----+-----+-----+-----+\n",
        "                 /      |       |      \\\n",
        "                /       |       |       \\\n",
        "               /        |       |        \\\n",
        "              /         |       |         \\\n",
        "             /          |       |          \\\n",
        "            /           |       |           \\\n",
        " +-----------+ +-----------+ +-----------+ +-----------+\n",
        " | Process 0 | | Process 1 | | Process 2 | | Process 3 |\n",
        " +-+-------+-+ +-+-------+-+ +-+-------+-+ +-+-------+-+\n",
        "   | Value |     | Value |     | Value |     | Value |\n",
        "   |   0   |     |  100  |     |  200  |     |  300  |\n",
        "   +-------+     +-------+     +-------+     +-------+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75qL1Rsjok36",
        "outputId": "5a10fd0a-b1e4-490a-f227-3e3c5d8e17e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpiScatter.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpiScatter.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <mpi.h>\n",
        "\n",
        "int main(int argc, char* argv[])\n",
        "{\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    // Get number of processes and check that 4 processes are used\n",
        "    int size;\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "    if(size != 4)\n",
        "    {\n",
        "        printf(\"This application is meant to be run with 4 processes.\\n\");\n",
        "        MPI_Abort(MPI_COMM_WORLD, EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Determine root's rank\n",
        "    int root_rank = 0;\n",
        "\n",
        "    // Get my rank\n",
        "    int my_rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
        "\n",
        "    // Define my value\n",
        "    int my_value;\n",
        "\n",
        "    if(my_rank == root_rank)\n",
        "    {\n",
        "        int buffer[4] = {0, 100, 200, 300};\n",
        "        printf(\"Values to scatter from process %d: %d, %d, %d, %d.\\n\", my_rank, buffer[0], buffer[1], buffer[2], buffer[3]);\n",
        "        MPI_Scatter(buffer, 1, MPI_INT, &my_value, 1, MPI_INT, root_rank, MPI_COMM_WORLD);\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        MPI_Scatter(NULL, 1, MPI_INT, &my_value, 1, MPI_INT, root_rank, MPI_COMM_WORLD);\n",
        "    }\n",
        "\n",
        "    printf(\"Process %d received value = %d.\\n\", my_rank, my_value);\n",
        "\n",
        "    MPI_Finalize();\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwQrATZSok37"
      },
      "outputs": [],
      "source": [
        "!mpicc mpiScatter.c -o mpiScatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17IuKG55ok37",
        "outputId": "14721e6c-6d20-46df-f5db-d8d152337d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Values to scatter from process 0: 0, 100, 200, 300.\n",
            "Process 0 received value = 0.\n",
            "Process 2 received value = 200.\n",
            "Process 1 received value = 100.\n",
            "Process 3 received value = 300.\n"
          ]
        }
      ],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./mpiScatter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNkQaiYVkz9L"
      },
      "source": [
        "## Estudo de Caso: Integração Numérica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGrA_4USkz9M",
        "outputId": "52a6afea-1ead-4a5c-c4bf-108438ee8fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting integral-mpi.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile integral-mpi.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <mpi.h>\n",
        "\n",
        "/* f(x) function from which the integral will be calculated. */\n",
        "double f(double x)\n",
        "{\n",
        " return 100 * x + sin(2 * x * M_PI);\n",
        "}\n",
        "\n",
        "/* Calculates the integral of the function betweens point a and b. */\n",
        "double integral(double a, double b, int n)\n",
        "{\n",
        "   double h, s = 0, result;\n",
        "   int i;\n",
        "\n",
        "   h = (b - a) / n;\n",
        "\n",
        "   for (i = 0; i < n; i++)\n",
        "   {\n",
        "     s += f(a + h * (i + 0.5));\n",
        "   }\n",
        "\n",
        "   result = h * s;\n",
        "\n",
        "   return result;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "   double result = 0, result2, partial_result = 0;\n",
        "   int steps = atoi(argv[1]);\n",
        "   int rank, size;\n",
        "\n",
        "   MPI_Init(&argc, &argv);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "   MPI_Status status;\n",
        "\n",
        "   //sequential\n",
        "   double startS = MPI_Wtime();\n",
        "      result2 = integral(0, 1, steps);\n",
        "   double endS = MPI_Wtime();\n",
        "\n",
        "  //parallel MPI\n",
        "   double startP = MPI_Wtime();\n",
        "      partial_result = integral(rank/size, (rank + 1)/size, steps);\n",
        "      MPI_Reduce(&partial_result, &result, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);\n",
        "   double endP = MPI_Wtime();\n",
        "\n",
        "   if(rank == 0){\n",
        "      printf(\"(S) %f\\t%f\\n\",  endS - startS, result2);\n",
        "      printf(\"(P) %f\\t%f\\n\",  endP - startP, result);\n",
        "      printf(\"Speedup =  %f\\n\", (endS - startS)/(endP - startP) );\n",
        "\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHrFpKunkz9M"
      },
      "outputs": [],
      "source": [
        "!mpicc integral-mpi.c -o integral-mpi -fopenmp -lm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBlaUNWbkz9M",
        "outputId": "5189b234-e8c1-41ca-f27b-7816eec00846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(S) 15.734721\t50.000000\n",
            "(P) 12.548931\t50.000000\n",
            "Speedup =  1.253869\n"
          ]
        }
      ],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 8 ./integral-mpi 100000000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOT8a4eIo6Av"
      },
      "source": [
        "## Exercício Proposto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqw0HHSQpKLU"
      },
      "source": [
        "A partir do seguinte trecho de código, pergunta-se:  \n",
        "\n",
        "a) Qual a funcionalidade do código abaixo.   \n",
        "\n",
        "b) Como seria a compilação e execução desse código.  \n",
        "\n",
        "c) Qual a funcionalidade do comando `MPI_Barrier`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiSwQEs8qR5u",
        "outputId": "d6453f4f-e3b5-46ec-aeaf-1bd53dc4acc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpi_matrix_example.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi_matrix_example.c\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    int rank, size;\n",
        "    const int N = 2;  // Matrix size is N x N\n",
        "    int matrix[N][N];\n",
        "    int local_data;\n",
        "\n",
        "    // Initialize MPI\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    if (size != N*N) {\n",
        "        if (rank == 0) {\n",
        "            printf(\"This example requires %d processes.\\n\", N*N);\n",
        "        }\n",
        "        MPI_Finalize();\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    // Each process initializes its portion of the matrix with its rank\n",
        "    local_data = rank;\n",
        "\n",
        "    int row = rank / N;\n",
        "    int col = rank % N;\n",
        "    matrix[row][col] = local_data;\n",
        "\n",
        "    // Barrier synchronization\n",
        "    MPI_Barrier(MPI_COMM_WORLD);\n",
        "\n",
        "    // Root process gathers the matrix data from all processes\n",
        "    int received_data[N*N];\n",
        "    MPI_Gather(&local_data, 1, MPI_INT, received_data, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "    // Root process prints the matrix\n",
        "    if (rank == 0) {\n",
        "        printf(\"Matrix:\\n\");\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                printf(\"%d \", received_data[i*N + j]);\n",
        "            }\n",
        "            printf(\"\\n\");\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Finalize MPI\n",
        "    MPI_Finalize();\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mpicxx mpi_matrix_example.c -o mpi_matrix_example-mpi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix:\n",
            "0 1 \n",
            "2 3 \n"
          ]
        }
      ],
      "source": [
        "!mpirun -np 4 ./mpi_matrix_example-mpi"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
